

import torch
import json
from model_inference import predict_sentiment, config
from typing import List, Dict
import numpy as np
from colorama import init, Fore, Style

# Inicjalizacja kolorÃ³w
init(autoreset=True)


# =========================================================================
# PRZYPADKI TESTOWE
# =========================================================================

TEST_CASES = [
    # === POZYTYWNE ===
    {
        "text": "Jedzenie byÅ‚o absolutnie wyÅ›mienite",
        "expected": {"jedzenie": 5, "cena": 3, "obsÅ‚uga": 3, "atmosfera": 3},
        "category": "Pozytywne - jedzenie"
    },
    {
        "text": "Pizza pyszna, obsÅ‚uga Å›wietna, tanio i klimatycznie",
        "expected": {"jedzenie": 5, "cena": 5, "obsÅ‚uga": 5, "atmosfera": 5},
        "category": "Pozytywne - wszystko"
    },
    {
        "text": "Super burger, kelnerzy pomocni, Å‚adne wnÄ™trze",
        "expected": {"jedzenie": 5, "cena": 3, "obsÅ‚uga": 5, "atmosfera": 4},
        "category": "Pozytywne - mix"
    },

    # === NEGATYWNE ===
    {
        "text": "Jedzenie okropne i zimne",
        "expected": {"jedzenie": 1, "cena": 3, "obsÅ‚uga": 3, "atmosfera": 3},
        "category": "Negatywne - jedzenie"
    },
    {
        "text": "Wszystko fatalne - jedzenie niesmaczne, obsÅ‚uga niegrzeczna, drogo i brudno",
        "expected": {"jedzenie": 1, "cena": 1, "obsÅ‚uga": 1, "atmosfera": 1},
        "category": "Negatywne - wszystko"
    },
    {
        "text": "Pizza zimna, kelnerzy aroganccy, ceny kosmiczne",
        "expected": {"jedzenie": 1, "cena": 1, "obsÅ‚uga": 1, "atmosfera": 3},
        "category": "Negatywne - mix"
    },

    # === MIESZANE (TRUDNE!) ===
    {
        "text": "Jedzenie pyszne, ale obsÅ‚uga fatalna",
        "expected": {"jedzenie": 5, "cena": 3, "obsÅ‚uga": 1, "atmosfera": 3},
        "category": "Mieszane - pozytyw + negatyw"
    },
    {
        "text": "Super kuchnia, ale ceny absurdalnie wysokie",
        "expected": {"jedzenie": 5, "cena": 1, "obsÅ‚uga": 3, "atmosfera": 3},
        "category": "Mieszane - dobra jakoÅ›Ä‡, zÅ‚a cena"
    },
    {
        "text": "Tanio i smacznie, ale czekaliÅ›my godzinÄ™",
        "expected": {"jedzenie": 4, "cena": 5, "obsÅ‚uga": 1, "atmosfera": 3},
        "category": "Mieszane - dobra cena, zÅ‚a obsÅ‚uga"
    },
    {
        "text": "PiÄ™kne wnÄ™trze i miÅ‚a obsÅ‚uga, ale jedzenie mdÅ‚e",
        "expected": {"jedzenie": 2, "cena": 3, "obsÅ‚uga": 4, "atmosfera": 5},
        "category": "Mieszane - zÅ‚a jakoÅ›Ä‡, dobra reszta"
    },

    # === NEUTRALNE ===
    {
        "text": "PrzeciÄ™tnie, nic specjalnego",
        "expected": {"jedzenie": 3, "cena": 3, "obsÅ‚uga": 3, "atmosfera": 3},
        "category": "Neutralne"
    },
    {
        "text": "Normalnie, ani dobrze ani Åºle",
        "expected": {"jedzenie": 3, "cena": 3, "obsÅ‚uga": 3, "atmosfera": 3},
        "category": "Neutralne"
    },

    # === ASPEKT: CENA ===
    {
        "text": "Ceny bardzo przystÄ™pne i rozsÄ…dne",
        "expected": {"jedzenie": 3, "cena": 5, "obsÅ‚uga": 3, "atmosfera": 3},
        "category": "Cena - tanie"
    },
    {
        "text": "Ceny drapiÄ™Å¼ne i wygÃ³rowane",
        "expected": {"jedzenie": 3, "cena": 1, "obsÅ‚uga": 3, "atmosfera": 3},
        "category": "Cena - drogie"
    },

    # === ASPEKT: OBSÅUGA ===
    {
        "text": "Kelnerzy super profesjonalni i pomocni",
        "expected": {"jedzenie": 3, "cena": 3, "obsÅ‚uga": 5, "atmosfera": 3},
        "category": "ObsÅ‚uga - dobra"
    },
    {
        "text": "CzekaliÅ›my 40 minut, obsÅ‚uga beznadziejna",
        "expected": {"jedzenie": 3, "cena": 3, "obsÅ‚uga": 1, "atmosfera": 3},
        "category": "ObsÅ‚uga - zÅ‚a"
    },

    # === ASPEKT: ATMOSFERA ===
    {
        "text": "PiÄ™kne wnÄ™trze, eleganckie i stylowe",
        "expected": {"jedzenie": 3, "cena": 3, "obsÅ‚uga": 3, "atmosfera": 5},
        "category": "Atmosfera - dobra"
    },
    {
        "text": "HaÅ‚aÅ›liwie, brudno i ciasno",
        "expected": {"jedzenie": 3, "cena": 3, "obsÅ‚uga": 3, "atmosfera": 1},
        "category": "Atmosfera - zÅ‚a"
    },

    # === EDGE CASES ===
    {
        "text": "Najlepsza pizza w Å¼yciu! Absolutnie rewelacyjna!",
        "expected": {"jedzenie": 5, "cena": 3, "obsÅ‚uga": 3, "atmosfera": 3},
        "category": "Edge - superlatywy"
    },
    {
        "text": "Tragedia, najgorsza restauracja ever",
        "expected": {"jedzenie": 1, "cena": 1, "obsÅ‚uga": 1, "atmosfera": 1},
        "category": "Edge - skrajnie negatywne"
    },
]


# =========================================================================
# FUNKCJE TESTOWE
# =========================================================================

def get_color_for_score(score: int) -> str:
    """ZwrÃ³Ä‡ kolor dla oceny"""
    if score >= 4:
        return Fore.GREEN
    elif score >= 3:
        return Fore.YELLOW
    else:
        return Fore.RED


def get_emoji_for_score(score: int) -> str:
    """ZwrÃ³Ä‡ emoji dla oceny"""
    emojis = {1: "ğŸ˜¡", 2: "ğŸ˜", 3: "ğŸ˜", 4: "ğŸ™‚", 5: "ğŸ˜"}
    return emojis.get(score, "â“")


def calculate_accuracy(predicted: int, expected: int, tolerance: int = 1) -> bool:
    """SprawdÅº czy predykcja jest poprawna (z tolerancjÄ…)"""
    return abs(predicted - expected) <= tolerance


def test_single_case(case: Dict) -> Dict:
    """Testuj pojedynczy przypadek"""
    text = case["text"]
    expected = case["expected"]

    # Predykcja
    result = predict_sentiment(text)
    scores = result["scores"]
    confidences = result["confidences"]

    # Mapowanie
    predictions = {
        config.ASPECTS[i]: scores[i]
        for i in range(len(config.ASPECTS))
    }

    confidence_dict = {
        config.ASPECTS[i]: confidences[i]
        for i in range(len(config.ASPECTS))
    }

    # SprawdÅº accuracy
    results = {}
    all_correct = True

    for aspect in config.ASPECTS:
        pred = predictions[aspect]
        exp = expected[aspect]
        correct = calculate_accuracy(pred, exp, tolerance=1)

        results[aspect] = {
            "predicted": pred,
            "expected": exp,
            "correct": correct,
            "confidence": confidence_dict[aspect]
        }

        if not correct:
            all_correct = False

    return {
        "text": text,
        "category": case["category"],
        "results": results,
        "all_correct": all_correct,
        "avg_confidence": np.mean(list(confidence_dict.values()))
    }


def print_test_result(test_result: Dict):
    """WyÅ›wietl wynik testu"""
    text = test_result["text"]
    category = test_result["category"]
    results = test_result["results"]
    all_correct = test_result["all_correct"]
    avg_conf = test_result["avg_confidence"]

    # Status
    status = f"{Fore.GREEN}âœ“ PASS" if all_correct else f"{Fore.RED}âœ— FAIL"

    print(f"\n{status}{Style.RESET_ALL}")
    print(f"Kategoria: {Fore.CYAN}{category}{Style.RESET_ALL}")
    print(f"Tekst: \"{text}\"")
    print(f"Avg Confidence: {avg_conf:.2%}")

    # SzczegÃ³Å‚y per aspekt
    print("\nWyniki:")
    for aspect, data in results.items():
        pred = data["predicted"]
        exp = data["expected"]
        conf = data["confidence"]
        correct = data["correct"]

        color = Fore.GREEN if correct else Fore.RED
        check = "âœ“" if correct else "âœ—"
        emoji_pred = get_emoji_for_score(pred)
        emoji_exp = get_emoji_for_score(exp)

        print(f"  {color}{check}{Style.RESET_ALL} {aspect:12s}: "
              f"pred={emoji_pred} {pred} | exp={emoji_exp} {exp} | "
              f"conf={conf:.2%}")


def run_all_tests():
    """Uruchom wszystkie testy"""
    print("=" * 80)
    print(f"{Fore.CYAN}ğŸ§ª SZCZEGÃ“ÅOWE TESTY MODELU BERT ABSA{Style.RESET_ALL}")
    print("=" * 80)

    all_results = []
    categories_stats = {}

    # Uruchom testy
    for i, case in enumerate(TEST_CASES, 1):
        print(f"\n{Fore.YELLOW}{'â”€'*80}{Style.RESET_ALL}")
        print(f"{Fore.YELLOW}Test {i}/{len(TEST_CASES)}{Style.RESET_ALL}")

        result = test_single_case(case)
        print_test_result(result)

        all_results.append(result)

        # Statystyki per kategoria
        category = result["category"].split(" - ")[0]
        if category not in categories_stats:
            categories_stats[category] = {"pass": 0, "total": 0}

        categories_stats[category]["total"] += 1
        if result["all_correct"]:
            categories_stats[category]["pass"] += 1

    # PODSUMOWANIE
    print(f"\n\n{Fore.CYAN}{'='*80}{Style.RESET_ALL}")
    print(f"{Fore.CYAN}ğŸ“Š PODSUMOWANIE WYNIKÃ“W{Style.RESET_ALL}")
    print(f"{Fore.CYAN}{'='*80}{Style.RESET_ALL}")

    # OgÃ³lne statystyki
    total_tests = len(all_results)
    passed_tests = sum(1 for r in all_results if r["all_correct"])
    overall_accuracy = passed_tests / total_tests

    avg_confidence = np.mean([r["avg_confidence"] for r in all_results])

    print(f"\nğŸ“ˆ OgÃ³lne statystyki:")
    print(f"   Testy: {passed_tests}/{total_tests} ({overall_accuracy:.1%})")
    print(f"   Åšrednia pewnoÅ›Ä‡: {avg_confidence:.1%}")

    # Per kategoria
    print(f"\nğŸ“‹ Statystyki per kategoria:")
    for category, stats in sorted(categories_stats.items()):
        pass_rate = stats["pass"] / stats["total"]
        color = Fore.GREEN if pass_rate >= 0.7 else Fore.YELLOW if pass_rate >= 0.5 else Fore.RED
        print(f"   {color}{category:20s}: {stats['pass']}/{stats['total']} ({pass_rate:.1%}){Style.RESET_ALL}")

    # Per aspekt
    print(f"\nğŸ¯ Accuracy per aspekt:")
    aspect_accuracy = {aspect: [] for aspect in config.ASPECTS}

    for result in all_results:
        for aspect, data in result["results"].items():
            aspect_accuracy[aspect].append(1 if data["correct"] else 0)

    for aspect in config.ASPECTS:
        acc = np.mean(aspect_accuracy[aspect])
        color = Fore.GREEN if acc >= 0.7 else Fore.YELLOW if acc >= 0.5 else Fore.RED
        print(f"   {color}{aspect:12s}: {acc:.1%}{Style.RESET_ALL}")

    # Rekomendacje
    print(f"\nğŸ’¡ Rekomendacje:")
    if overall_accuracy >= 0.75:
        print(f"   {Fore.GREEN}âœ… Model dziaÅ‚a ÅšWIETNIE! Gotowy do produkcji.{Style.RESET_ALL}")
    elif overall_accuracy >= 0.60:
        print(f"   {Fore.YELLOW}ğŸŸ¡ Model dziaÅ‚a DOBRZE. MoÅ¼na uÅ¼yÄ‡, ale sÄ… przestrzenie do poprawy.{Style.RESET_ALL}")
    else:
        print(f"   {Fore.RED}âŒ Model wymaga wiÄ™cej treningu lub lepszych danych.{Style.RESET_ALL}")

    if avg_confidence < 0.5:
        print(f"   {Fore.YELLOW}âš ï¸  Niska pewnoÅ›Ä‡ modelu - rozwaÅ¼ wiÄ™cej epok treningowych.{Style.RESET_ALL}")

    print(f"\n{Fore.CYAN}{'='*80}{Style.RESET_ALL}")

    return all_results, overall_accuracy


# =========================================================================
# MAIN
# =========================================================================

if __name__ == "__main__":
    try:
        results, accuracy = run_all_tests()

        # Zapisz wyniki
        output_file = "./test_results.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                "overall_accuracy": accuracy,
                "total_tests": len(results),
                "passed_tests": sum(1 for r in results if r["all_correct"]),
                "results": [
                    {
                        "text": r["text"],
                        "category": r["category"],
                        "correct": r["all_correct"],
                        "confidence": r["avg_confidence"]
                    }
                    for r in results
                ]
            }, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ Wyniki zapisane w {output_file}")

    except Exception as e:
        print(f"\n{Fore.RED}âŒ BÅÄ„D: {e}{Style.RESET_ALL}")
        import traceback
        traceback.print_exc()